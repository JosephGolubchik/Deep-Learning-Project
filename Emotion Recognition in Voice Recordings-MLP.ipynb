{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition in Voice Recordings\n",
    "##### Joseph Golubchik (209195353), Johann Thuillier (336104120), Shlomi Wenberger (203179403)\n",
    "\n",
    "The aim of our project is to use logistic regression to classify a persons emotional state from a recording of him speaking.  \n",
    "\n",
    "## Dataset\n",
    "The dataset we used is “The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)”  \n",
    "https://zenodo.org/record/1188976  \n",
    "\n",
    "The database contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression. All conditions are available in three modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4), and Video-only (no sound). We used only the speach files and not the song files, and used only the audio files and not the videos.\n",
    "\n",
    "Speech file contains 1440 files: 60 trials per actor x 24 actors = 1440. The labels for each file will be taken from the filenames: The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics: Filename identifiers Modality (01 = full-AV, 02 = video-only, 03 = audio-only). Vocal channel (01 = speech, 02 = song). Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised). Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion. Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\"). Repetition (01 = 1st repetition, 02 = 2nd repetition). Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract only the features from data_xy\n",
    "def getXvalues(data_xy):\n",
    "    x_values = []\n",
    "    for data in data_xy:\n",
    "        x_values.append(data[0])\n",
    "    return x_values\n",
    "\n",
    "# Function to extract only the labels from data_xy\n",
    "def getYvalues(data_xy):\n",
    "    y_values = []\n",
    "    for data in data_xy:\n",
    "        y_values.append(data[1])\n",
    "    return y_values\n",
    "\n",
    "# Sigmoid function\n",
    "def logistic_fun(z):\n",
    "    return 1/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files = 1440 ,Number of actors = 24\n",
      "Number of train examples = 1007 ,Number of test examples = 433\n"
     ]
    }
   ],
   "source": [
    "# Loading the filenames from the folder with the audio files.\n",
    "filenames = []\n",
    "\n",
    "for i in range(1,25):\n",
    "    if (i < 10):\n",
    "        folderNum = \"0\"+str(i)\n",
    "    else:\n",
    "        folderNum = str(i)\n",
    "    for file in os.listdir('audio/Actor_'+folderNum):\n",
    "        filenames.append('Actor_'+folderNum+'/'+file)\n",
    "        \n",
    "\n",
    "\n",
    "# Shuffling the filenames array.\n",
    "random.shuffle(filenames)\n",
    "\n",
    "# Spliting the dataset into train and test files,\n",
    "# 70% train and 30% test.\n",
    "num_train = int(len(filenames)*0.7)\n",
    "num_test = len(filenames) - num_train\n",
    "\n",
    "print(\"Number of files =\",len(filenames),\",Number of actors =\",int(len(filenames)/60))\n",
    "print(\"Number of train examples =\",num_train,\",Number of test examples =\",num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time: 168.61646682778337 Seconds\n"
     ]
    }
   ],
   "source": [
    "data_x_train = []\n",
    "data_x_test = []\n",
    "data_y_train = []\n",
    "data_y_test = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# For each of the training examples,\n",
    "# extract from each file its Mel-frequency cepstral coefficients (MFCCs)\n",
    "# and append the mfccs to the array that stores the features of each train file - data_x_train.\n",
    "# look at the filename and create a label for the example,\n",
    "# Where the 8'th character determines the label.\n",
    "# Ex: filename[7] == 3 => label: [0,0,1,0,0,0,0,0]\n",
    "for filename in filenames[:num_train]:\n",
    "    if filename != 'Actor_17/03-01-06-01-02-01-17.wav111':\n",
    "        data, sampling_rate = librosa.load(\"audio/\" + filename, sr=22050*2, res_type='kaiser_fast', duration=2.5, offset=0.5)\n",
    "        sampling_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0)\n",
    "        if len(mfccs) != 216:\n",
    "            print(filename)\n",
    "        data_x_train.append(mfccs)\n",
    "        label = np.zeros(8)\n",
    "        label[int(filename[16])-1] = 1\n",
    "        data_y_train.append(label)\n",
    "\n",
    "# Do the same for the testing examples.\n",
    "for filename in filenames[num_train:]:\n",
    "    if filename != 'Actor_17/03-01-06-01-02-01-17.wav111':\n",
    "        data, sampling_rate = librosa.load(\"audio/\" + filename, sr=22050*2, res_type='kaiser_fast', duration=2.5, offset=0.5)\n",
    "        sampling_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0)\n",
    "        data_x_test.append(mfccs)\n",
    "        label = np.zeros(8)\n",
    "        label[int(filename[16])-1] = 1\n",
    "        data_y_test.append(label)\n",
    "    \n",
    "stop_time = timeit.default_timer()\n",
    "print('Loading time:', stop_time - start_time, \"Seconds\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 216) (433,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data_x_train), np.shape(data_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow requires the y array that it gets to be of the shape (none, 1)\n",
    "# This converts our data_y arrays from the shape (none, ) to the required shape (none, 1)\n",
    "# ex: [0, 1, 1, 1, 0] => [[0], [1], [1], [1], [0]]\n",
    "data_y_train_correct = []\n",
    "data_y_test_correct = []\n",
    "\n",
    "for val in data_y_train:\n",
    "    val_arr = []\n",
    "    val_arr.append(val)\n",
    "    data_y_train_correct.append(val_arr)\n",
    "    \n",
    "for val in data_y_test:\n",
    "    val_arr = []\n",
    "    val_arr.append(val)\n",
    "    data_y_test_correct.append(val_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new array that will contain tuples where the first element is the features of the example,\n",
    "# and the second element is the label of the example.\n",
    "# This is neccesary so we can shuffle the order of the examples around after each training epoch.\n",
    "# data_xy_train = []\n",
    "# for i in range(len(data_x_train)):\n",
    "#     data_xy_train.append( (data_x_train[i], data_y_train_correct[i]) )\n",
    "    \n",
    "# data_xy_test = []\n",
    "# for i in range(len(data_x_test)):\n",
    "#     data_xy_test.append( (data_x_test[i], data_y_test_correct[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_train = []\n",
    "for i in range(len(data_x_train)):\n",
    "    if len(data_x_train[i]) == 216:\n",
    "        data_xy_train.append( (data_x_train[i], data_y_train[i]) )\n",
    "    \n",
    "data_xy_test = []\n",
    "for i in range(len(data_x_test)):\n",
    "    if len(data_x_test[i]) == 216:\n",
    "        data_xy_test.append( (data_x_test[i], data_y_test[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 216) (431, 216)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(getXvalues(data_xy_train)), np.shape(getXvalues(data_xy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in getXvalues(data_xy_train):\n",
    "    if len(data) != 216:\n",
    "        print(len(data), count, filenames[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0: Accuracy: 0.14849187\n",
      "Epoch500: Accuracy: 0.1438515\n",
      "Epoch1000: Accuracy: 0.15777262\n",
      "Epoch1500: Accuracy: 0.20417634\n",
      "Epoch2000: Accuracy: 0.19953597\n",
      "Epoch2500: Accuracy: 0.20417634\n",
      "Epoch3000: Accuracy: 0.21345708\n",
      "Epoch3500: Accuracy: 0.20185615\n",
      "Epoch4000: Accuracy: 0.21345708\n",
      "Epoch4500: Accuracy: 0.22273782\n",
      "Epoch5000: Accuracy: 0.225058\n",
      "Epoch5500: Accuracy: 0.23665893\n",
      "Epoch6000: Accuracy: 0.24825986\n",
      "Epoch6500: Accuracy: 0.2412993\n",
      "Epoch7000: Accuracy: 0.24593967\n",
      "Epoch7500: Accuracy: 0.24593967\n",
      "Epoch8000: Accuracy: 0.25290024\n",
      "Epoch8500: Accuracy: 0.25058004\n",
      "Epoch9000: Accuracy: 0.26914153\n",
      "Epoch9500: Accuracy: 0.2552204\n",
      "Accuracy: 0.25290024\n",
      "runtime:  85.97175560119285\n"
     ]
    }
   ],
   "source": [
    "features = len(data_xy_train[0][0])\n",
    "hidden_layer_nodes = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 8])\n",
    "W1 = tf.Variable(tf.truncated_normal([features,hidden_layer_nodes], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hidden_layer_nodes]))\n",
    "z1 = tf.add(tf.matmul(x,W1),b1)\n",
    "a1 = tf.nn.relu(z1)\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_layer_nodes,8], stddev=0.1))\n",
    "b2 = tf.Variable(0.)\n",
    "z2 = tf.matmul(a1,W2) + b2\n",
    "y = tf.nn.softmax(z2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])+0.1*tf.nn.l2_loss(W))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# accuracy_arr = np.array()\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for i in range(10000):\n",
    "    sess.run(train_step, feed_dict={x:getXvalues(data_xy_train), y_:getYvalues(data_xy_train)})\n",
    "    if i % 500 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        print('Epoch '+str(i)+':', \"Accuracy:\", sess.run(accuracy, feed_dict={x:getXvalues(data_xy_test), y_:getYvalues(data_xy_test)}))\n",
    "#     random.shuffle(data_xy_train)\n",
    "    \n",
    "stop_time = timeit.default_timer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"Accuracy:\", sess.run(accuracy, feed_dict={x:getXvalues(data_xy_test), y_:getYvalues(data_xy_test)}))\n",
    "print('runtime: ', stop_time - start_time)  \n",
    "\n",
    "# Inconsistent\n",
    "# Accuracy: 0.62931037, iter=5000, rate=0.0006, 10 nodes\n",
    "# Accuracy: 0.6637931, iter=10000, rate=0.0006, 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [431] vs. [433]\n\t [[{{node Equal_2}} = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_4, ArgMax_5)]]\n\nCaused by op 'Equal_2', defined at:\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-131-ca1a932de4d6>\", line 32, in <module>\n    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2949, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [431] vs. [433]\n\t [[{{node Equal_2}} = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_4, ArgMax_5)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [431] vs. [433]\n\t [[{{node Equal_2}} = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_4, ArgMax_5)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-c5f98aa63687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgetXvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_xy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata_y_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgetXvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_xy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata_y_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [431] vs. [433]\n\t [[{{node Equal_2}} = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_4, ArgMax_5)]]\n\nCaused by op 'Equal_2', defined at:\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-131-ca1a932de4d6>\", line 32, in <module>\n    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2949, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [431] vs. [433]\n\t [[{{node Equal_2}} = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_4, ArgMax_5)]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(correct_prediction, feed_dict={x:getXvalues(data_xy_test), y_:data_y_test})\n",
    "ans = np.array(sess.run(correct_prediction, feed_dict={x:getXvalues(data_xy_test), y_:data_y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
