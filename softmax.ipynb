{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Course - Exercise 2\n",
    "This is a softmax prototype, with classes: Happy, Sad, Angry\n",
    "At first we tried using logistic regression with 2 classes: Happy, Sad\n",
    "This didn't work well enough, adn we got ~0.5 accuracy.\n",
    "We tried the same method but to predict Male or Female, and this worked much better with ~0.8 accuracy.\n",
    "Eventually we tried doing softmax with Happy, Sad, Angry, to see if the problem was a weak model for happy and sad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of files= 600 ,num of actors= 10.0\n"
     ]
    }
   ],
   "source": [
    "# Load the filenames from the folder containing the dataset\n",
    "filenames = []\n",
    "for file in os.listdir('audio2'):\n",
    "    filenames.append(file)\n",
    "print(\"num of files=\",len(filenames),\",num of actors=\",len(filenames)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max, min = 76117, 53310\n",
    "# start, end = 21000/sampling_rate, 47424/sampling_rate\n",
    "# wave_length = end-start\n",
    "num_train = int(len(filenames)*0.7)\n",
    "num_test = len(filenames) - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in filenames[:num_train]:\n",
    "#     data, sampling_rate = librosa.load(\"audio/\" + filename, res_type='kaiser_fast', duration=end, offset=start)\n",
    "#     print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['feature'])\n",
    "# for index, y in enumerate(filenames):\n",
    "#     data, sampling_rate = librosa.load(\"audio/\" + filename, res_type='kaiser_fast', duration=end, offset=start)\n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=data, n_mfcc=25,), axis=0)\n",
    "#     data_x_train.append(-(mfccs)/100)\n",
    "    \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:  35.29020342662443\n"
     ]
    }
   ],
   "source": [
    "data_x_train = []\n",
    "data_x_test = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for filename in filenames[:num_train]:\n",
    "    data, sampling_rate = librosa.load(\"audio2/\" + filename, sr=22050*2, res_type='kaiser_fast', duration=2.5, offset=0.5)\n",
    "    sampling_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0)\n",
    "    data_x_train.append(mfccs)\n",
    "    \n",
    "for filename in filenames[num_train:]:\n",
    "    data, sampling_rate = librosa.load(\"audio2/\" + filename, sr=22050*2, res_type='kaiser_fast', duration=2.5, offset=0.5)\n",
    "    sampling_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0)\n",
    "    data_x_test.append(mfccs)\n",
    "    \n",
    "stop_time = timeit.default_timer()\n",
    "print('runtime: ', stop_time - start_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_train = []\n",
    "data_y_test = []\n",
    "\n",
    "for filename in filenames[:num_train]:\n",
    "    if filename[7] == '1':\n",
    "        data_y_train.append([1,0,0,0,0,0,0,0])\n",
    "    elif filename[7] == '2':\n",
    "        data_y_train.append([0,1,0,0,0,0,0,0])\n",
    "    elif filename[7] == '3':\n",
    "        data_y_train.append([0,0,1,0,0,0,0,0])\n",
    "    elif filename[7] == '4':\n",
    "        data_y_train.append([0,0,0,1,0,0,0,0])\n",
    "    elif filename[7] == '5':\n",
    "        data_y_train.append([0,0,0,0,1,0,0,0])\n",
    "    elif filename[7] == '6':\n",
    "        data_y_train.append([0,0,0,0,0,1,0,0])\n",
    "    elif filename[7] == '7':\n",
    "        data_y_train.append([0,0,0,0,0,0,1,0])\n",
    "    elif filename[7] == '8':\n",
    "        data_y_train.append([0,0,0,0,0,0,0,1])\n",
    "        \n",
    "for filename in filenames[num_train:]:\n",
    "    if filename[7] == '1':\n",
    "        data_y_test.append([1,0,0,0,0,0,0,0])\n",
    "    elif filename[7] == '2':\n",
    "        data_y_test.append([0,1,0,0,0,0,0,0])\n",
    "    elif filename[7] == '3':\n",
    "        data_y_test.append([0,0,1,0,0,0,0,0])\n",
    "    elif filename[7] == '4':\n",
    "        data_y_test.append([0,0,0,1,0,0,0,0])\n",
    "    elif filename[7] == '5':\n",
    "        data_y_test.append([0,0,0,0,1,0,0,0])\n",
    "    elif filename[7] == '6':\n",
    "        data_y_test.append([0,0,0,0,0,1,0,0])\n",
    "    elif filename[7] == '7':\n",
    "        data_y_test.append([0,0,0,0,0,0,1,0])\n",
    "    elif filename[7] == '8':\n",
    "        data_y_test.append([0,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes every value in data_y to an array\n",
    "# ex: [0, 1, 1, 1, 0] => [[0], [1], [1], [1], [0]]\n",
    "data_y_train_correct = []\n",
    "data_y_test_correct = []\n",
    "\n",
    "for val in data_y_train:\n",
    "    val_arr = []\n",
    "    val_arr.append(val)\n",
    "    data_y_train_correct.append(val_arr)\n",
    "    \n",
    "for val in data_y_test:\n",
    "    val_arr = []\n",
    "    val_arr.append(val)\n",
    "    data_y_test_correct.append(val_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_train = []\n",
    "for i in range(len(data_x_train)):\n",
    "    data_xy_train.append( (data_x_train[i], data_y_train[i]) )\n",
    "    \n",
    "data_xy_test = []\n",
    "for i in range(len(data_x_test)):\n",
    "    data_xy_test.append( (data_x_test[i], data_y_test[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXvalues(data_xy):\n",
    "    x_values = []\n",
    "    for data in data_xy:\n",
    "        x_values.append(data[0])\n",
    "    return x_values\n",
    "\n",
    "def getYvalues(data_xy):\n",
    "    y_values = []\n",
    "    for data in data_xy:\n",
    "        y_values.append(data[1])\n",
    "    return y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fun(z):\n",
    "    return 1/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333334\n",
      "runtime:  3.0462227212083235\n"
     ]
    }
   ],
   "source": [
    "0.33333334\n",
    "features = len(data_xy_train[0][0])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 8])\n",
    "W = tf.Variable(tf.zeros([features, 8]))\n",
    "b = tf.Variable(tf.zeros([8]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])+0.1*tf.nn.l2_loss(W))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.00002).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for i in range(950):\n",
    "    sess.run(train_step, feed_dict={x:getXvalues(data_xy_train), y_:getYvalues(data_xy_train)})\n",
    "#     random.shuffle(data_xy_train)\n",
    "    \n",
    "stop_time = timeit.default_timer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x:getXvalues(data_xy_test), y_:getYvalues(data_xy_test)}))\n",
    "print('runtime: ', stop_time - start_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = []\n",
    "\n",
    "data, sampling_rate = librosa.load(\"yosi3.wav\", sr=22050*2, res_type='kaiser_fast', duration=2.5, offset=0.5)\n",
    "sampling_rate = np.array(sampling_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0)\n",
    "file_test.append(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.argmax(y,1)+1, feed_dict={x:file_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
